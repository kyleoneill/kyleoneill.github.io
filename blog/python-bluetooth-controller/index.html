<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="The developer portfolio for Kyle O&#x27;Neill">
        <meta name="author" content="Kyle O&#x27;Neill">
       
        <!-- favicon -->
        <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
        <link rel="manifest" href="/site.webmanifest">
        <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
        <meta name="msapplication-TileColor" content="#ffffff">
        <meta name="theme-color" content="#ffffff">

        <!-- fonts and styles -->
        <link href="https://fonts.googleapis.com/css?family=Rubik:400,700" rel="stylesheet">
        <link href="https://kyleoneill.dev/style.css" rel="stylesheet">

        <title>
            
                Python Bluetooth Controller using OCR
            
        </title>
    </head>
    <body>
        <div class="section header">
            <div class="logo">
                <a href="/" class="logo-image" width="100"></a>
            </div>
            <div class="links">
                
                
                    <a href="https://kyleoneill.dev/about/">About</a>
                
                    <a href="https://kyleoneill.dev/resume/">Resume</a>
                
                
                    
                    <a href="https://kyleoneill.dev/blog/">Blog</a>
                
            </div>
            <!-- search would go here -->
        </div>
        
<div class="section title">
    Python Bluetooth Controller using OCR
    <div class="subtitle">
        October 26, 2020
    </div>
</div>
<div class="section content">
    <h1 id="led-strips-and-video-games">LED Strips and Video Games</h1>
<p>It's a well known fact that computer gamers love RGB. A cheap and easy way to add RGB lighting to a computer setup is with an LED light strip and a simple Bluetooth strip only costs a few dollars on Amazon. The only pain is that they need to be manually controlled; a strip isn't really integrated with the computer setup. Python can be used to solve this issue, directly integrating a Bluetooth LED strip with computer processes. I thought it would be fun to have my LED strip change colors while playing <a href="https://na.leagueoflegends.com/en-us/">League of Legends</a> to represent my health in the game. The strip would be red at very low health and green at high health values.</p>
<h1 id="reading-a-computer-screen">Reading a Computer Screen</h1>
<p>PIL stands for Python Imaging Library and was a library which allowed Python to manipulate image files. PIL was discontinued but has been succeeded by a fork to the project called <a href="https://pillow.readthedocs.io/en/stable/">Pillow</a>. Beyond the capability to edit images, Pillow allows us to stream images directly off of a computer monitor.</p>
<h2 id="tesseract-ocr">Tesseract OCR</h2>
<p>One of the largest draws of Python is how its syntax and ecosystem allow for complicated expressions and tasks to be utilized in few lines of code. Python is routinely used in machine learning applications, like OCR (<a href="https://en.wikipedia.org/wiki/Optical_character_recognition">Optical Character Recognition</a>). <a href="https://github.com/tesseract-ocr/tesseract">Tesseract OCR</a> is an open source OCR engine maintained by Google. <a href="https://pypi.org/project/pytesseract/">PyTesseract</a> is a wrapper for Tesseract allowing Python to use the OCR engine.</p>
<h2 id="putting-it-all-together">Putting It All Together</h2>
<p>Making a simple screen reader with OCR capability is surprisingly easy.</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#b48ead;">from </span><span style="color:#c0c5ce;">PIL </span><span style="color:#b48ead;">import </span><span style="color:#c0c5ce;">ImageGrab</span><span style="color:#c0c5ce;">
</span><span style="color:#b48ead;">import </span><span style="color:#c0c5ce;">pytesseract</span><span style="color:#c0c5ce;">
x = </span><span style="color:#d08770;">0</span><span style="color:#c0c5ce;">
y = </span><span style="color:#d08770;">0</span><span style="color:#c0c5ce;">
offx = </span><span style="color:#d08770;">100</span><span style="color:#c0c5ce;">
offy = </span><span style="color:#d08770;">100</span><span style="color:#c0c5ce;">
img = ImageGrab.</span><span style="color:#bf616a;">grab</span><span style="color:#c0c5ce;">(</span><span style="color:#bf616a;">bbox</span><span style="color:#c0c5ce;">=(x, y, x + offx, y + offy))</span><span style="color:#c0c5ce;">
probable_string = pytesseract.</span><span style="color:#bf616a;">image_to_string</span><span style="color:#c0c5ce;">(img)</span><span style="color:#c0c5ce;">
</span><span style="color:#96b5b4;">print</span><span style="color:#c0c5ce;">(</span><span style="color:#b48ead;">f</span><span style="color:#c0c5ce;">&quot;</span><span style="color:#a3be8c;">Tesseract thinks our image says: </span><span style="color:#c0c5ce;">{probable_string}&quot;)</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>The above snippet will create a square image out of your computer monitor starting from the top left corner with a length and width of 100 pixels. It passes this image to Tesseract, which will try to turn that image into a string.</p>
<p>Surprised about how easy it was to come this far, I assumed that I was essentially finished with the &quot;read values from the screen&quot; portion of the program. I got into a League of Legends match and pointed the program to the area of the screen where my health was and took damage, expecting the <code>probable_string</code> variable in the above snippet to return my health value. The string did not show health values, it did not even return numbers. The output look like garbled and randomized text.</p>
<h2 id="training-tesseract">Training Tesseract</h2>
<p>Tesseract uses machine learning to convert an image into a string. Out of the box, Tesseract is usually accurate and minor inaccuracies can be fixed by fiddling with its config settings. I assumed that Tesseract was failing to understand health values from League of Legends because the game uses a custom font that was never in any of Tesseract's training models. Luckily, it's possible to train your own model.</p>
<p>I got into another match and took screenshots at various health values ensuring that I had at least one example of all ten integers (0 through 9). For reference, this is what a health bar in League of Legends looks like. The green bar at the top is health, the blue bar below it is mana. I was not planning on using the mana value, but it is helpful here to create a larger training set of numbers.</p>
<p><img src="https://kyleoneill.dev/blog/python-bluetooth-controller/ex_health.png" alt="health" /></p>
<p>I added an image processing step to the code snippet above to make the values easier for Tesseract to read. I used this processing on the health bar screenshots to do the same for the training data. The below code snippet details this processing.</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">process_image</span><span style="color:#c0c5ce;">(</span><span style="color:#bf616a;">img</span><span style="color:#c0c5ce;">):</span><span style="color:#c0c5ce;">
    R, G, B = img.</span><span style="color:#bf616a;">convert</span><span style="color:#c0c5ce;">(&quot;</span><span style="color:#a3be8c;">RGB</span><span style="color:#c0c5ce;">&quot;).</span><span style="color:#bf616a;">split</span><span style="color:#c0c5ce;">()</span><span style="color:#c0c5ce;">
    r = R.</span><span style="color:#bf616a;">load</span><span style="color:#c0c5ce;">()</span><span style="color:#c0c5ce;">
    g = G.</span><span style="color:#bf616a;">load</span><span style="color:#c0c5ce;">()</span><span style="color:#c0c5ce;">
    b = B.</span><span style="color:#bf616a;">load</span><span style="color:#c0c5ce;">()</span><span style="color:#c0c5ce;">
    w, h = img.size</span><span style="color:#c0c5ce;">
    threshold = </span><span style="color:#d08770;">170</span><span style="color:#c0c5ce;">
    threshold_two = </span><span style="color:#d08770;">10</span><span style="color:#c0c5ce;">
    </span><span style="color:#b48ead;">for </span><span style="color:#c0c5ce;">i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span style="color:#c0c5ce;">(w):</span><span style="color:#c0c5ce;">
        </span><span style="color:#b48ead;">for </span><span style="color:#c0c5ce;">j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span style="color:#c0c5ce;">(h):</span><span style="color:#c0c5ce;">
            </span><span style="color:#b48ead;">if </span><span style="color:#c0c5ce;">r[i, j] &lt; threshold or g[i, j] &lt; threshold or b[i, j] &lt; threshold:</span><span style="color:#c0c5ce;">
                r[i, j] = </span><span style="color:#d08770;">0</span><span style="color:#c0c5ce;">
            </span><span style="color:#b48ead;">if </span><span style="color:#96b5b4;">abs</span><span style="color:#c0c5ce;">(r[i, j] - g[i, j]) &gt; threshold_two or </span><span style="color:#96b5b4;">abs</span><span style="color:#c0c5ce;">(g[i, j] - b[i, j]) &gt; threshold_two or </span><span style="color:#96b5b4;">abs</span><span style="color:#c0c5ce;">(r[i, j] - b[i, j]) &gt; threshold_two:</span><span style="color:#c0c5ce;">
                r[i, j] = </span><span style="color:#d08770;">0</span><span style="color:#c0c5ce;">
            r[i, j] = </span><span style="color:#d08770;">255 </span><span style="color:#c0c5ce;">- r[i, j]</span><span style="color:#c0c5ce;">
    img = Image.</span><span style="color:#bf616a;">merge</span><span style="color:#c0c5ce;">(&quot;</span><span style="color:#a3be8c;">RGB</span><span style="color:#c0c5ce;">&quot;, (R, R, R))</span><span style="color:#c0c5ce;">
    </span><span style="color:#b48ead;">return </span><span style="color:#c0c5ce;">img</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>This function splits an image into its red, green, and blue channels. It then iterates through each pixel to correct the image. If a pixel is too dark or too colorful, it's assumed to be background and set to white. The white text is set to black. This gives the image a higher contrast and numbers are more clear. After processing the health looked more like the following:</p>
<p><img src="https://kyleoneill.dev/blog/python-bluetooth-controller/processed_health.png" alt="processed_health" /></p>
<p>Next, box files must be generated for each health image. A box file is a series of symbols and coordinates describing the text content of an image and is used during training so Tesseract knows when a model is correct. Tesseract can generate box files but the file will almost certainly need to be manually corrected. The generation can be done on a terminal like this: </p>
<pre style="background-color:#2b303b;">
<code><span style="color:#bf616a;">$</span><span style="color:#c0c5ce;"> tesseract my_training_set.my_photo.exp0.png my_training_set.font.exp0 batch.nochop makebox</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>The first four lines of a corrected box file for the processed health image just above will look like this:</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#c0c5ce;">6 3 21 12 34 0</span><span style="color:#c0c5ce;">
0 13 21 22 34 0</span><span style="color:#c0c5ce;">
3 23 21 31 34 0</span><span style="color:#c0c5ce;">
/ 37 21 44 34 0</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>After all of the box files are finished Tesseract can train a new model. The training process is described <a href="http://cjas.org/%7Ejamesy/tesseract-training.html">here</a>. Once the model is trained, using it is as simple as moving the generated <code>.traineddata</code> file into Tesseract's <code>tessdata</code> folder and then referring to it in Tesseract's config, like this:</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#c0c5ce;">health = pytesseract.</span><span style="color:#bf616a;">image_to_string</span><span style="color:#c0c5ce;">(img, </span><span style="color:#bf616a;">lang</span><span style="color:#c0c5ce;">=&quot;</span><span style="color:#a3be8c;">symbols</span><span style="color:#c0c5ce;">&quot;)</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>Trying the process again with the new model improves accuracy a great deal - Tesseract now recognizes that all of the characters it sees in the health bar are numbers and it's output is extremely consistent. Unfortunately, this still has not solved the problem. My model always mistook &quot;2&quot; for &quot;8&quot; and &quot;1&quot; for &quot;7&quot;. This could be because the training set was not large enough. I added more images to the training set focusing on those two integers bringing the total to seven images, but the problem persisted.</p>
<h2 id="the-simple-route-prevails">The Simple Route Prevails</h2>
<p>In the end I was able to get Tesseract to be correct &gt;99% of the time by processing the image slightly more and by using the engine's configuration settings. Even though the training route did not work, it was a lot of fun to learn how to train my own model. In the <code>image_to_string</code> method I set my config to:</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#c0c5ce;">config=&quot;--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789/&quot;</span><span style="color:#c0c5ce;">
</span></code></pre>
<ul>
<li>psm stands for &quot;page segmentation mode&quot; and --psm 6 tells Tesseract to assume that the image is going to be a single uniform block of text.</li>
<li>oem stands for &quot;OCR Engine mode&quot; and --oem 3 tells Tesseract to use the default setting</li>
<li>-c allows us to set config variables. The variable <code>tessedit_char_whitelist</code> tells Tesseract what characters it can use when turning an image into text. For this program the integers 0-9 are needed as well as the &quot;/&quot; between current and max health values.</li>
</ul>
<p>In my <code>process_image</code> function I resized the image to be larger:</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#c0c5ce;">w, h = img.size</span><span style="color:#c0c5ce;">
img = img.</span><span style="color:#bf616a;">resize</span><span style="color:#c0c5ce;">((w * </span><span style="color:#d08770;">3</span><span style="color:#c0c5ce;">, h * </span><span style="color:#d08770;">3</span><span style="color:#c0c5ce;">))</span><span style="color:#c0c5ce;">
</span></code></pre>
<p>The larger image, the configuration settings, and some fiddling with the threshold numbers responsible for the image contrast allowed Tesseract to correctly read health values.</p>
<h1 id="communicating-with-an-led-strip">Communicating with an LED Strip</h1>
<p>My LED strip uses Bluetooth and can be changed by two methods: a controller that it came with or using an app on the phone. I could use <a href="http://manpages.ubuntu.com/manpages/cosmic/man1/gatttool.1.html">gatttool</a> to communicate with it as well, but this requries three three pieces of information:</p>
<ol>
<li>The MAC address of the strip</li>
<li>The identifier that begins communication</li>
<li>The data that actually tells the strip what to do</li>
</ol>
<p>I was able to find two repositories on GitHub that had information about the the last piece of information, so I just had to find the first two.</p>
<h2 id="finding-a-mac-address">Finding a MAC Address</h2>
<p>Unfortunately the MAC was not printed anywhere on the strip's Bluetooth receptor or in any of the documentation it came with. Fortunately, Android phones can be used to get information about Bluetooth connections. With developer mode turned on, I enabled &quot;Bug Report Shortcut&quot; and &quot;Bluetooth HCI Snoop Log&quot; in the developer options. I downloaded the light strips app from the Google Play Store and sent a few commands to it over Bluetooth to change its color. I then held down the power button, took a bug report, and emailed it to myself.</p>
<p>The bug report created a folder named &quot;dump&quot; with a lot of information in it but all I was interested in was the &quot;btsnoop_hci.log&quot; file, which I opened in WireShark. The address was not hard to find as Bluetooth was only used for a moment and to send a few commands</p>
<p><img src="https://kyleoneill.dev/blog/python-bluetooth-controller/wireshark.png" alt="bluetooth_capture" /></p>
<p>These packets gave me both the MAC address of the strip and the identifier required at the start of each request.</p>
<h2 id="sending-requests-using-flask">Sending Requests using Flask</h2>
<p>The exact code for the next section can be found in one of my <a href="https://github.com/kyleoneill/bluetooth_light_controller">GitHub repositories</a>. I created a very basic Flask server with only one endpoint which handles a POST request that changes the strip's color. I changed the screen reader from earlier to send a POST request to this endpoint every few milliseconds with the new color values. After receiving a request and doing some validation and hex transformation the Flask server uses gatttool to send a color change request:</p>
<pre style="background-color:#2b303b;">
<code><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">write_data</span><span style="color:#c0c5ce;">(</span><span style="color:#bf616a;">address</span><span style="color:#c0c5ce;">, </span><span style="color:#bf616a;">data</span><span style="color:#c0c5ce;">):</span><span style="color:#c0c5ce;">
    cmd = </span><span style="color:#b48ead;">f</span><span style="color:#c0c5ce;">&quot;</span><span style="color:#a3be8c;">gatttool -b </span><span style="color:#c0c5ce;">{address}</span><span style="color:#a3be8c;"> --char-write-req -a </span><span style="color:#c0c5ce;">{handle_hex}</span><span style="color:#a3be8c;"> -n </span><span style="color:#c0c5ce;">{data}&quot;</span><span style="color:#c0c5ce;">
    os.</span><span style="color:#bf616a;">system</span><span style="color:#c0c5ce;">(cmd)</span><span style="color:#c0c5ce;">
</span></code></pre><h1 id="success">Success</h1>
<p>Finally, health values from League of Legends will update the LED strip in real time. I broke up this program into two parts because I do not have Bluetooth on my Windows desktop and gatttool is a Linux tool. It is possible to run gatttool on <a href="https://docs.microsoft.com/en-us/windows/wsl/about">WSL</a> and get a Bluetooth adapter, but it was easier to put the Flask server on a <a href="https://www.raspberrypi.org/">Raspberry Pi</a> I already had available. This segmentation also allows for other programs to control the LED strip as well.</p>
<p>Thanks for reading, if you have any questions or comments, feel free to <a href="/about#contact-me">contact me</a>.</p>

</div>
<div class="section navigation">
    
    
</div>

        <div class="section footer">
            &copy; 2021 Kyle O&#x27;Neill
        </div>
    </body>
</html>
